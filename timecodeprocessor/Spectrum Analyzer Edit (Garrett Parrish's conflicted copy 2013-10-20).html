
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/html"><head><title>
    Loading and playing a sound with the Web Audio API
</title><script type="text/javascript" async="" src="http://www.google-analytics.com/ga.js"></script>
    <script src="jquery-1.10.2.min.js" type="text/javascript"></script>
    <script src="audio_analyzer.js"></script><style>


        * {
            font-family: sans-serif;
        }

    </style></head><body style="background-color: white;"><h2>
    Graph will start animating when music is loaded
</h2><p>
    For more information on how this is done look at
    <a href="http://www.smartjava.org/content/exploring-html5-web-audio-visualizing-sound">
        this article.
    </a>
    .

</p><canvas id="canvas" style="display: block;" height="325" width="1000"></canvas><script type="text/javascript">
    // create the audio context (chrome only for now)
    var context = new webkitAudioContext();
    var audioAnalyzer = new AudioAnalyzer();
    var audioBuffer;
    var sourceNode;
    var analyser;
    var javascriptNode;
    var currentSample = 0;



    // get the context from the canvas to draw on
    var ctx = $("#canvas").get()[0].getContext("2d");

    // create a gradient for the fill. Note the strange
    // offset, since the gradient is calculated based on
    // the canvas, not the specific element we draw
    var gradient = ctx.createLinearGradient(0,0,0,300);
    gradient.addColorStop(1,'#000000');
    gradient.addColorStop(0.75,'#ff0000');
    gradient.addColorStop(0.25,'#ffff00');
    gradient.addColorStop(0,'#ffffff');


    // load the sound
    loadSound("music&code.wav");
    //setupAudioNodes();

    function setupAudioNodes(buffer) {

        // setup a javascript node
        //javascriptNode = context.createJavaScriptNode(256, 1, 1);

        // connect to destination, else it isn't called
        //javascriptNode.connect(context.destination);



        // setup a analyzer
        analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0;
        analyser.fftSize = 256;
        analyser.minDecibels=-100;
        analyser.maxDecibels=-30;

        //first filter
        filter1 = context.createBiquadFilter();
        filter1.type = 2;  // bandpass
        filter1.frequency.value = 18500;
        filter1.Q.value = 10;

        //second filter
        filter2 = context.createBiquadFilter();
        filter2.type = 2;  // bandpass
        filter2.frequency.value = 19500;
        filter2.Q.value = 10;

        //third filter
        filter3 = context.createBiquadFilter();
        filter3.type = 4;  // highshelf
        filter3.frequency.value = 18000;
        filter3.gain.value = 40;

        //fourth filter
        filter4 = context.createBiquadFilter();
        filter4.type = 3;  // lowshelf
        filter4.frequency.value = 18000;
        filter4.gain.value = -40;

        //fifth filter
        filter5 = context.createBiquadFilter();
        filter5.type = 4;  // highshelf
        filter5.frequency.value = 20000;
        filter5.gain.value = -40;

        //sixth filter
        filter6 = context.createBiquadFilter();
        filter6.type = 3;  // lowshelf
        filter6.frequency.value = 20000;
        filter6.gain.value = 40;

        //seventh filter
        filter7 = context.createBiquadFilter();
        filter7.type = 6;  // bandstop
        filter7.frequency.value = 19000;
        filter7.Q.value = 4;




        // create a buffer source node
        sourceNode = context.createBufferSource();
        sourceNode.buffer = buffer;
        sourceNode.connect(filter1);
        filter1.connect(filter2);
        filter2.connect(filter3);
        filter3.connect(filter4);
        filter4.connect(filter5);
        filter5.connect(filter6);
        filter6.connect(filter7);
        filter7.connect(analyser);
        //analyser.connect(javascriptNode);

        sourceNode.connect(context.destination);

        // when the javascript node is called
        // we use information from the analyzer node
        // to draw the volume
        /*
        javascriptNode.onaudioprocess = function() {

            console.log("Start: ",context.currentTime);
            var value = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteTimeDomainData(value);
            console.log("Time since last call: ", context.currentTime-context.lastTime);
            //console.log("Time domain data: ", value);
            context.lastTime=context.currentTime;
            //console.log(sourceNode.playbackState);
            if (sourceNode.playbackState == sourceNode.UNSCHEDULED_STATE){
                sourceNode.playbackRate.value = 1;
                console.log("Turning on: ", context.currentTime);
                sourceNode.noteOn(0);
                console.log("Turned on: ", context.currentTime);
                audioAnalyzer.currentSample = 0;
            }
            if (sourceNode.playbackState == sourceNode.PLAYING_STATE) {
            audioAnalyzer.currentSample+=256;



            // get the average for the first channel
            var longarray =  new Float32Array(analyser.frequencyBinCount);
            analyser.getFloatFrequencyData(longarray);

            var array =  new Float32Array(analyser.frequencyBinCount);
            for (var i=0; i<longarray.length; i++) {
                array[i]=(longarray[i]-analyser.minDecibels);
            }

            audioAnalyzer.readCurrentPulse(array);
            //console.log(audioAnalyzer.pulseData);


            // clear the current state
            ctx.clearRect(0, 0, 1000, 325);

            // set the fill style
            ctx.fillStyle=gradient;
            /*
             document.write('Current sample: ');
             document.write(array.length);
             document.write(' [')  ;
             for ( var i = 0; i < (array.length); i++ ){
             var value = array[i];
             document.write(value);document.write(', ') ;
             }
             document.writeln(']');
             document.writeln('---------------');


            //drawSpectrum(array);
            console.log("Finish: ",context.currentTime);
            console.log('---------------');
            }

        }
        */
        //setInterval(timedEvent,5.8049886621315);
        setInterval(timedEvent, 0.1);

    }

    function timedEvent() {
    console.log("Start: ",context.currentTime);
    var value = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteTimeDomainData(value);
    console.log("Time since last call: ", context.currentTime-context.lastTime);
    //console.log("Time domain data: ", value);
    context.lastTime=context.currentTime;
    //console.log(sourceNode.playbackState);
    if (sourceNode.playbackState == sourceNode.UNSCHEDULED_STATE){
        sourceNode.playbackRate.value = .1;
        console.log("Turning on: ", context.currentTime);
        sourceNode.noteOn(0);
        console.log("Turned on: ", context.currentTime);
        audioAnalyzer.currentSample = 0;
    }
    if (sourceNode.playbackState == sourceNode.PLAYING_STATE) {
        audioAnalyzer.currentSample+=256;



        // get the average for the first channel
        var longarray =  new Float32Array(analyser.frequencyBinCount);
        analyser.getFloatFrequencyData(longarray);

        var array =  new Float32Array(analyser.frequencyBinCount);
        for (var i=0; i<longarray.length; i++) {
            array[i]=(longarray[i]-analyser.minDecibels);
        }

        audioAnalyzer.readCurrentPulse(array);
        //console.log(audioAnalyzer.pulseData);


        // clear the current state
        ctx.clearRect(0, 0, 1000, 325);

        // set the fill style
        ctx.fillStyle=gradient;
        /*
         document.write('Current sample: ');
         document.write(array.length);
         document.write(' [')  ;
         for ( var i = 0; i < (array.length); i++ ){
         var value = array[i];
         document.write(value);document.write(', ') ;
         }
         document.writeln(']');
         document.writeln('---------------');
         */

        //drawSpectrum(array);
        console.log("Finish: ",context.currentTime);
        console.log('---------------');
    }

    }



    // load the specified sound
    function loadSound(url) {
        var request = new XMLHttpRequest();
        request.open('GET', url, true);
        request.responseType = 'arraybuffer';

        // When loaded decode the data
        request.onload = function() {

            // decode the data
            context.decodeAudioData(request.response, function(buffer) {
                // when the audio is decoded play the sound
                setupAudioNodes(buffer);
            }, onError);
        }
        request.send();
    }


    function playSound(buffer) {
        sourceNode.buffer = buffer;
        //channel = sourceNode.buffer.getChannel(0);
        //console.log(channel.getSlice(0,256));
        //sourceNode.noteOn(0);
        //document.write("Just started playing");

    }

    // log if an error occurs
    function onError(e) {
        console.log(e);
    }

    function drawSpectrum(array) {
        for ( var i = 0; i < (array.length); i++ ){
            var value = array[i];

            ctx.fillRect(i*5,325-value,3,325);
            //  console.log([i,value])
        }
    };


</script></body></html>
